{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notebook is doing couple of simple things and is divided on universal fuctions whicht except scrapping part could be used elsewhere\n",
    "\n",
    "Main purpose is to get list of the interesting jobs as a  pandas dataframe saved on *.h5 file for later use/comparison with the help of \n",
    "BeautifulSoup, re\n",
    "\n",
    "to achieve that you need to define start webpage(start_url) with name of the jobs/place you are looking for \n",
    "Functions inside are \n",
    "\n",
    "Then datafraframe is saved with datastamp and compared to last saved df to check what is new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np \n",
    "import re\n",
    "import datetime\n",
    "import os,glob\n",
    "import json\n",
    "from json.decoder import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing list of existing(previously created by scrapping) pandas linkedin .h5 files\n",
    "search_dir = \"/home/lubuntu/scrap/glass/\" #directory where from where h5 is read s\n",
    "def list_per_time(search_dir=search_dir):\n",
    "    files = [x for x in (filter(os.path.isfile, glob.glob(search_dir + \"glassdoor*.h5\"))) ] \n",
    "    files_sorted= sorted(files, key=os.path.getmtime)\n",
    "    print(files_sorted[:10])\n",
    "    return files_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start web address \n",
    "start_url= 'https://www.glassdoor.com/Job/berlin-biotechnology-jobs-SRCH_IL.0,6_IC2622109_KE7,20.htm?fromAge=3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the source tree format like\n",
    "\n",
    "def beautify(url):\n",
    "    hdr = {'User-Agent': 'Marozilla/5.0'}\n",
    "    req = Request(url,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "\n",
    "    return BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = beautify(start_url)\n",
    "#retrieving information how many pages with jobs ads are\n",
    "def how_many_pages(start_url):\n",
    "    how_many_pages_job= jobs.findAll('div', {'class' : \"cell middle hideMob padVertSm\"})\n",
    "    for x, result in enumerate(how_many_pages_job):\n",
    "        print('last page is --->', result.text[-2:])\n",
    "    return result.text[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last page is --->  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages=how_many_pages(start_url)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_urls=[]# based on the number of summary webpages we generate their names in the table to later check\n",
    "def gen_table_urls(start_url, pages ): #based on number of pages with links function should generate web addres for every page\n",
    "    pp='&&p='\n",
    "    for i in range (int(pages)):\n",
    "#         print(i+1,'-->', start_url[:-14]+'_IP'+str(i+1)+start_url[-14:])\n",
    "        start_urls.append(start_url[:-14]+'_IP'+str(i+1)+start_url[-14:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_table_urls(start_url, pages ) #table with wabpages to check is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.glassdoor.com/Job/berlin-biotechnology-jobs-SRCH_IL.0,6_IC2622109_KE7,20_IP1.htm?fromAge=3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [] #table with all relevant links to jobs\n",
    "for x, job in enumerate(start_urls):\n",
    "    job = beautify(start_urls[x])\n",
    "    j_links=job.findAll('a', attrs={'href': re.compile(\"^https://www.glassdoor.com/partner/jobListing.htm?\")}) #filtering links to webpages of selected jobs\n",
    "    jobs_links = [link.get('href') for link in j_links] #creating a list of job links\n",
    "    for i in jobs_links: \n",
    "        if i not in res:\n",
    "            res.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are -->  7 jobs and links\n"
     ]
    }
   ],
   "source": [
    "print('There are --> ',len(res), 'jobs and links')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patterns to remove from description\n",
    "clean_patterns= ['&lt;', '/&gt', ';br',';li',';/ul','li&gt;', 'h2&gt;', 'ul&gt;', 'br ;', '/', 'div&gt;', 'h3&gt;', 'h4&gt;' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "description='XXXXXXX' #when there is problem with reading field with job description to be able go further fill with XXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_descri(description=description, clean_patterns=clean_patterns): # function which is cleaning job description from tags defined before\n",
    "    \n",
    "    for x,clean in enumerate(clean_patterns):\n",
    "#         print(x)\n",
    "        pattern=re.compile(clean_patterns[x])\n",
    "        description= pattern.sub(\" \", description)\n",
    "    pattern=re.compile(r\"strong&gt;\")\n",
    "    description= pattern.sub(\"\\n\\n *---*\", description)\n",
    "#     print(description)\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_empty_record(job_dict): #when there is a problem with urls fill record with default data so the scrapping is going further\n",
    "                      \n",
    "        description=job_dict\n",
    "#         job_descr=clean_job_descri(description)\n",
    "        job_name = 'XXXXXXX'\n",
    "        company_name = 'XXXXXXX'\n",
    "        job_descr=job_name\n",
    "        timestamp = datetime.datetime.now()\n",
    "        datePosted = '2020-07-01'\n",
    "        validThrough = '2020-07-01'\n",
    "        job_url = 'url'\n",
    "        place_name='addressLocality'\n",
    "        place_name_region = 'addressRegion'\n",
    "        latitude = '52.5177'\n",
    "        longitude = '13.4055'\n",
    "        employmentType = 'UNKNOWN'\n",
    "        return job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #collecting information from dictionary like structure\n",
    "    def create_record(job_dict):\n",
    "                      \n",
    "        description=job_dict['description']\n",
    "        clean_job_descri(description)  \n",
    "        job_name = job_dict['title']\n",
    "        company_name = job_dict['hiringOrganization']['name']\n",
    "        job_descr=clean_job_descri(description)\n",
    "        timestamp = datetime.datetime.now()\n",
    "        datePosted = job_dict['datePosted']\n",
    "        validThrough = job_dict['validThrough']\n",
    "        job_url = job_dict['url']\n",
    "        place_name=job_dict['jobLocation']['address']['addressLocality']\n",
    "        place_name_region = job_dict['jobLocation']['address']['addressRegion']\n",
    "        latitude = job_dict['jobLocation']['geo']['latitude']\n",
    "        longitude = job_dict['jobLocation']['geo']['longitude']\n",
    "        employmentType = job_dict['employmentType']\n",
    "        return job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_record(url): #retrieving information from webpages if there are some json errors on url  using create_emty_record_function\n",
    "    j = beautify(url)\n",
    "    try:\n",
    "        job_dict=json.loads(r\"\".join(j.find(\"script\", {\"type\":\"application/ld+json\"}).contents), strict=False) #there is there job description location etc\n",
    "        job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType=create_record(job_dict)\n",
    "    except JSONDecodeError as e:\n",
    "        print('there was some json error with url:', url)\n",
    "        job_dict=j.find(\"script\", {\"type\":\"application/ld+json\"}).contents\n",
    "        job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType=create_empty_record(job_dict)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    return job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================temporary  tables to store  info from webpages\n",
    "job=[] #ok\n",
    "company=[] #ok\n",
    "place=[] #ok\n",
    "job_d=[] #ok\n",
    "time_s=[] #ok\n",
    "datePosted_t=[] #ok\n",
    "validThrough_t=[] #ok\n",
    "job_url_t=[] #ok\n",
    "place_name_region_t =[]#ok\n",
    "latitude_t =[]#ok\n",
    "longitude_t =[]#ok\n",
    "employmentType_t =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating tables above with data from particular jobs\n",
    "def populate_temp_tables(url_list):\n",
    "       \n",
    "    for x,url in enumerate(url_list):\n",
    "        job_name, company_name, job_descr, timestamp, datePosted, validThrough, job_url, place_name, place_name_region, latitude, longitude, employmentType = get_job_record(url)\n",
    "        print(x+1,'-->',url)\n",
    "        job.append(job_name)\n",
    "        company.append(company_name)        \n",
    "        job_d.append(job_descr)\n",
    "        time_s.append(timestamp)\n",
    "        datePosted_t.append(datePosted)\n",
    "        validThrough_t.append(validThrough)\n",
    "        job_url_t.append(job_url)\n",
    "        place.append(place_name)\n",
    "        place_name_region_t.append(place_name_region)\n",
    "        latitude_t.append(latitude)\n",
    "        longitude_t.append(longitude)\n",
    "        \n",
    "    return job, company, place, job_d, time_s, datePosted_t, validThrough_t, job_url_t, place_name_region_t, latitude_t, longitude_t, employmentType_t\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=4120&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_254241d6&cb=1596015916299&jobListingId=3636213042\n",
      "2 --> https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=474845&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_1a0a2e08&cb=1596015916299&jobListingId=3635357570\n",
      "3 --> https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1034696&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_118504de&cb=1596015916299&jobListingId=3548761211\n",
      "4 --> https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=437149&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_8a473e24&cb=1596015916299&jobListingId=3589386064\n",
      "5 --> https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=437149&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_f2320bd8&cb=1596015916300&jobListingId=3612941022\n",
      "6 --> https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044072&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_e49db9b2&cb=1596015916300&jobListingId=3635236464\n",
      "7 --> https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044072&s=58&guid=0000017399f6347292143ecce622b619&src=GD_JOB_AD&t=SR&extid=1&exst=EL&ist=&ast=EL&slr=true&cs=1_75c61497&cb=1596015916300&jobListingId=3635236475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['DM.132.20b Research Associate (Postdoc) - Chronic and genetic kidney disease',\n",
       "  'Senior Specialist, Apheresis Audit - Germany (location Flexible)',\n",
       "  'Head of External Activation and Identity Management - Director',\n",
       "  'FRONT END DEVELOPER (M/F/D)',\n",
       "  'Senior Manager Health Economics & Market Access (m/f/d)',\n",
       "  'Laboratory technician (m/f/d)',\n",
       "  'Senior scientist (m/f/d)'],\n",
       " ['Charité',\n",
       "  'Bristol-Myers Squibb',\n",
       "  'Bayer',\n",
       "  'Clincase',\n",
       "  'BIOTRONIK',\n",
       "  'PERMACON GmbH Berlin',\n",
       "  'PERMACON GmbH Berlin'],\n",
       " ['Berlin', 'Berlin', 'Berlin', 'Berlin', 'Berlin', 'Berlin', 'Berlin'],\n",
       " ['  Unternehmensbeschreibung       Die Charit&amp;eacute; &amp;ndash; Universit&amp;auml;tsmedizin Berlin ist eine gemeinsame Einrichtung der Freien Universit&amp;auml;t Berlin und der Humboldt-Universit&amp;auml;t zu Berlin. Sie hat als eines der gr&amp;ouml;&amp;szlig;ten Universit&amp;auml;tsklinika Europas mit bedeutender Geschichte eine f&amp;uuml;hrende Rolle in Forschung, Lehre und Krankenversorgung inne. Aber auch als modernes Unternehmen mit Zertifizierungen im medizinischen, klinischen und im Management-Bereich tritt die Charit&amp;eacute; hervor.      Stellenbeschreibung     Einsatzgebiet       QUEST Center am BIH (AG Prof. Daniel Strech)\\n    \\nDie Stelle ist am QUEST Center for Transforming Biomedical Research des BIH (AG Prof. Dr. Dr. Daniel Strech) angesiedelt. Ziel des QUEST Centers ist die Optimierung der biomedizinischen Forschung bez&amp;uuml;glich Robustheit, Transparenz, Relevanz und Ethik. Unser Ansatz beinhaltet Forschung und Wirken in den Bereichen Metaresearch, Bioethik, Qualit&amp;auml;tssicherung, Lehre, Open Science, Inzentivierung und Belohnung sowie Forschung f&amp;uuml;r die und mit der &amp;Ouml;ffentlichkeit.\\n  \\nZur Unterst&amp;uuml;tzung diverser Forschungsvorhaben der AG Strech und Verarbeitung und Visualisierung gro&amp;szlig;er Datenmengen suchen wir Verst&amp;auml;rkung.      Aufgabengebiet   \\n\\n  \\n  Text und Data Mining Anwendung im Rahmen von wiss. Projekten   \\n  Durchf&amp;uuml;hrung von bibliometrischen Analysen im Rahmen von wiss. Projekten   \\n  Qualit&amp;auml;tskontrolle und Validierung von Algorithmen und Analysepipelines f&amp;uuml;r Forschungsergebnisse   \\n  Informationsextraktion zur Analyse und verbesserten Darstellung der Forschungsleistungen (insbes. Publikationen)   \\n  Beschaffung von (Text-)Daten aus vorhandenen internen Datenquellen sowie aus &amp;ouml;ffentlich zug&amp;auml;nglichen strukturierten wie unstrukturierten Datenquellen   \\n  Weiterentwicklung der wissenschaftlichen Strategie der Arbeitsgruppe, aktive Mitgestaltung am Arbeits- und Forschungsfeld des QUEST Center   \\n  Konzeption und Durchf&amp;uuml;hrung eigener wiss. Projekte   \\n  Die T&amp;auml;tigkeit dient der eigenen Weiterqualifizierung.   \\n   \\n\\n  Voraussetzungen   \\n\\n  \\n  erfolgreich abgeschlossenes wissenschaftliches Hochschulstudium der Informatik oder einer vergleichbaren Fachrichtung    \\n\\n  einschl&amp;auml;gige und fundierte Kenntnisse im Bereich Text und Data Mining sowie Bibliometrie   \\n  Programmiererfahrung (Python, R oder vergleichbare Programmiersprache)   \\n  Praktisches Wissen zu relevanten bibliografischen und technischen Konzepten, Standards und Protokollen (z.B. XML, APIs, Metadaten-Anwendungsprofile)   \\n  Kenntnisse zur qualit&amp;auml;tssichernden Arbeitsweise (z.B. Versionskontrolle, Unit-Tests) von VorteilErfahrung mit der Verarbeitung gro&amp;szlig;er Datenmengen und mit ETL-Prozessen von Vorteil    \\n\\n  Kenntnisse &amp;uuml;ber Forschungsinformationssysteme von Vorteil   \\n  Bereitschaft zur interdisziplin&amp;auml;ren Zusammenarbeit, hohes Ma&amp;szlig; an Kommunikations- und Teamf&amp;auml;higkeit   \\n  Strukturierte Arbeitsweise verbunden mit einem hohen Ma&amp;szlig; an analytischem Denkverm&amp;ouml;gen   \\n  sehr gute Deutsch- und Englischkenntnisse   \\n   \\n\\n  Arbeitsbedingungen &amp;amp; Leistungen     Einstellungstermin       01.10.2020      Besch&amp;auml;ftigungsdauer       3 Jahre gem. WissZeitVG      Arbeitszeit       volle Wochenarbeitszeit = 39 Stunden      Verg&amp;uuml;tung       Egr. 13 TV&amp;ouml;D VKA-K\\n  \\nDie Eingruppierung erfolgt unter Ber&amp;uuml;cksichtigung der Qualifikation und der pers&amp;ouml;nlichen Voraussetzungen.\\n  \\nHier finden Sie unsere Tarifvertr&amp;auml;ge www.charite.de karriere   \\n      Organisatorisches       Zusatzinformationen       Die Charit&amp;eacute; &amp;ndash; Universit&amp;auml;tsmedizin Berlin trifft ihre Personalentscheidungen nach Eignung, Bef&amp;auml;higung und fachlicher Leistung. Die Charit&amp;eacute; strebt eine Erh&amp;ouml;hung des Anteils von Frauen in F&amp;uuml;hrungspositionen an und fordert Frauen daher nachdr&amp;uuml;cklich auf, sich zu bewerben. Bei gleichwertiger Qualifikation werden Frauen im Rahmen der rechtlichen M&amp;ouml;glichkeiten vorrangig ber&amp;uuml;cksichtigt. Bewerbungen von Menschen mit Migrationshintergrund, die die Einstellungsvoraussetzungen erf&amp;uuml;llen, sind ausdr&amp;uuml;cklich erw&amp;uuml;nscht. Schwerbehinderte Bewerberinnen und Bewerber werden bei gleicher Qualifikation bevorzugt. Bei der Einstellung wird ein polizeiliches F&amp;uuml;hrungszeugnis, teilweise ein erweitertes F&amp;uuml;hrungszeugnis verlangt. Die Bewerbungsunterlagen k&amp;ouml;nnen leider nur dann zur&amp;uuml;ckgeschickt werden, wenn ein ausreichend frankierter R&amp;uuml;ckumschlag beigef&amp;uuml;gt ist. Eventuell anfallende Reisekosten k&amp;ouml;nnen nicht erstattet werden.      Datenschutzhinweis       Die Charit&amp;eacute; weist darauf hin, dass im Rahmen und zu Zwecken des Bewerbungsverfahrens an verschiedenen Stellen in der Charit&amp;eacute; (z.B. Fachbereich, Personalvertretung, Personalabteilung) personenbezogene Daten gespeichert und verarbeitet werden. Weiterhin k&amp;ouml;nnen die Daten innerhalb des Konzerns sowie an Stellen au&amp;szlig;erhalb (z.B. Beh&amp;ouml;rden) zur Wahrung berechtigter Interessen &amp;uuml;bermittelt bzw. verarbeitet werden. Mit Ihrer Bewerbung stimmen Sie unseren Datenschutz- und Nutzungsbestimmungen f&amp;uuml;r Bewerbungsverfahren, die Sie hier finden, zu.      Kennziffer       CC04-BIH-31.20      Bewerbungsfrist       11.08.2020      Bewerbungsanschrift       Bitte senden Sie s&amp;auml;mtliche Bewerbungsunterlagen, wie z.B.\\n  \\nAnschreiben, Lebenslauf, Zeugnisse, Urkunden usw. unter\\n  \\n \\n\\n *---*Angabe der Kennziffer an folgende Bewerberadresse:  \\n\\n *---*\\n    \\njobs@bihealth.de      Ansprechpartner f&amp;uuml;r Nachfragen       daniel.strech@charite.de         ',\n",
       "  'At Bristol Myers Squibb, we are inspired by a single vision - transforming patients&#039; lives through science.In oncology, hematology, immunology and cardiovascular disease - and one of the most diverse and promising pipelines in the industry - each of our passionate colleagues contribute to innovations that drive meaningful change. We bring a human touch to every treatment we pioneer. Join us and make a difference.\\n    \\nCelgene (a wholly owned subsidiary of Bristol-Myers Squibb) is a global biopharmaceutical company committed to changing the course of human health through bold pursuits in science, life-enhancing therapies, and a promise to always put patients first. At the core of that mission are the talented individuals who contribute their unique skill sets to help us drive innovation and deliver truly life-changing drugs for our patients. As we continue to pursue that mission, we&#039;re looking for talented professionals like you to join our team.\\n    \\nPrerequisites (As Applicable)\\n    \\n \\n\\n *---*Remote position to support audits throughout Germany - up to 70%-80% travel required  \\n\\n *---*\\n    \\nCell Therapy is at the epicenter of personalized medicine, and this exciting opportunity gives the candidate an opportunity to support the innovative and growing expansion of CAR-T therapies into European markets, for clinical and commercial purposes.\\n    \\nThe Specialist will support this objective through the auditing of apheresis collection centers, the sites where a patient&#039;s blood is withdrawn, packaged, and shipped according to specified procedures. This is a critical role within the Global Compliance team that requires someone with demonstrated experience conducting audits in a regulated environment, familiarity with blood and tissue-related regulations such as ATMPs, JACIE, and or familiarity with apheresis operations.\\n    \\nAdditionally, the Specialist will be able to contribute towards an annual risk assessment exercise, proposing and implementing audit process improvements, developing quarterly and annual metrics, and may have the opportunity to cross-train to support GMP GDP audits related to other CAR-T vendors such as material suppliers, manufacturing organizations, analytical labs, and more.\\n    \\n \\n\\n *---*In this role, you will be responsible for (but not limited to):  \\n\\n *---* \\n\\n  \\n  Contacting, coordinating, and scheduling an audit with the proper contacts at each Apheresis Collection center, including assembling the proper audit team, and determining travel logistics as needed     Completing and distributing an Audit Agenda, and Pre-Audit Document Request form to initiate pre-audit document review     Scheduling audit with the audited entities, according to audit schedule   \\n  Leading preparation meetings with internal stakeholders   \\n  Conducting audit at the apheresis site to ensure compliance to applicable regulations     Writing the audit report within provided timelines, and issuing reports along with Audit Findings Response Plans and or Audit Closure Memos     Assessing responses to audit observations and report all related metrics associated with each audit     In collaboration with management, lead the grading of observations and the identification of observation and effectiveness check requirements, ensuring that differences in opinion are resolved.     Reviewing and track all observation responses and observation actions that result from an audit, determine if observation responses are complete and if not, negotiate with observation owner(s).   \\n  Meeting with the business, audit team and SMEs to refine the risk assessment, ensuring all risks are identified, and finalizing the audit agenda     Ensuring that the audit owner and potential observation owners are identified; lead resolution of issues regarding identification of owners     Resolving schedule issues and escalate issues where appropriate     Contributing towards quarterly and annual audit program metrics     Proposing and implement improvements to the apheresis audit program.   \\n   \\n\\n \\n\\n *---*Your Profile:  \\n\\n *---*\\n\\n  \\n  BS BA degree with 5+ years of experience at a pharmaceutical or biotechnology under a GMP GTP environment, or 3+ years of healthcare experience directly related to apheresis-operations within a hospital or similarly regulated industry.     Must have an understanding of GMP and GTP regulations     Strong communication skills (verbal and written) in German &amp;amp; English,     Must be able to work independently and productively from a remote position     Experience working in a cross-functional discipline within a personalized medicine setting   \\n  Understanding or prior working knowledge within a personalized medicine, autologous cell therapy discipline   \\n  Commitment to self-development and ability to stay abreast of internal and external requirements.     Ability to travel up to 70% of the time, and at times, with limited notice   \\n   \\n\\nAround the world, we are passionate about making an impact on the lives of patients with serious diseases. Empowered to apply our individual talents and diverse perspectives in an inclusive culture, our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.\\n    \\nBristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives.\\n    ',\n",
       "  ' \\n\\n *---*Bayer is a global enterprise with core competencies in the Life Science fields of health care and agriculture. Its products and services are designed to benefit people and improve their quality of life. At Bayer you have the opportunity to be part of a culture where we value the passion of our employees to innovate and give them the power to change.  \\n\\n *---*\\n    \\n \\n\\n *---*Head of External Activation and Identity Management - Director  \\n\\n *---*\\n    \\n em&gt;Are you inspired by building and activating a compelling brand identity based on innovation and emerging trends in healthcare?  em&gt;\\n    \\n em&gt;Bayer has long embraced external innovation and partnering. We continuously build a reputation as a trusted partner driven by science and data, committed to openness and transparency in every step of the collaboration process. We are passionate about delivering results for our partners above and beyond the agreed upon terms.  em&gt;\\n    \\n em&gt;Innovation in healthcare is essential to deliver on Bayer&amp;rsquo;s vision of &amp;ldquo;Health for All, Hunger for None&amp;rdquo;. Here, partnerships and external innovation are key.  em&gt;\\n    \\n em&gt;Reporting to Executive VP of BD&amp;amp;L and Member of the Pharmaceuticals Executive Committee, this position plays an integral role in ensuring both our internal stakeholders as well as our current and future partners have full awareness and visibility of Bayer&amp;rsquo;s credentials and contemporary offering as a partner of choice.  em&gt;\\n    \\n em&gt;To this end, this role will require the skills and expertise to plan, conceptualize, develop and implement highly engaging internal communications whilst also ensuring creative and targeted external communications and high impact brand activation in line with our vision to ultimately make a difference to patients.  em&gt;\\n    \\n em&gt;Internally, you will be the key liaison to other partnering functions in Bayer to ensure coordinated efforts and coherent messaging on point with strategy. Working across a global matrix organization, you will be adept at collaboration and securing alignment between BD&amp;amp;L and other teams to progress organizational goals and meaningfully leverage synergies.  em&gt;\\n    \\n em&gt;Externally the position holder will focus on developing and executing high-impact partnering appearances for Bayer Pharmaceuticals across key external platforms including signature industry events like JP Morgan or Bio Conventions in US, Europe and Asia, as well as other established and new industry conferences in healthcare and biotechnology involving speaking opportunities  em&gt;\\n    \\n em&gt;To be well positioned for this role, ideally you will have worked across a combination of disciplines including corporate communications, managing high-profile campaigns as part of brand building, large scale signature events, external partnerships, and cutting-edge integrated communications including a track record in working across digital platforms.  em&gt;\\n    \\n em&gt; \\n\\n *---*What does success look like?  \\n\\n *---* Through highly effective and well-orchestrated positioning of Bayer Pharmaceuticals BD&amp;amp;L, key internal and external stakeholders are fully informed and engaged in our vision through enhanced awareness, visibility and reputation.\\n    \\nPlese note: This position could also be located in Whippany (US).  em&gt;\\n    \\n \\n\\n *---*YOUR TASKS AND RESPONSEBILITIES  \\n\\n *---*\\n\\n  \\n\\n\\t  Drive and maximize strategic opportunities for the BD&amp;amp;L organization to position and deliver the Bayer collaboration story to a variety of audiences (internal and external) and articulate the company&amp;rsquo;s vision, mission and key priorities (e.g. speaking engagements and campaigns).   \\n  Provide strategic counsel and support to the Head of Pharmaceuticals BD&amp;amp;L on all internal as well as external communications (e.g. speeches, narrative talking points, articles, video messages, external presentations, digital collaterals)   \\n  Design structure and timing of internal messages through a variety of media and communication channels.   \\n  Build and deliver messages that resonate with diverse audiences.   \\n  Plan and execute global business update meetings for BD&amp;amp;L community (e.g. Town halls, webcasts, newsletters, blogs, etc.), implement and manage the global Intranet for BD&amp;amp;L, and support special project communications, e.g. new BD&amp;amp;L Strategy, Bayer Pharma Strategy, Bayer M&amp;amp;A projects   \\n  Act as the single-point of contact for Bayer PH Head of Executive Communications and Strategic PR to leverage Collaborate-to-Cure communication messages also within Bayer Pharmaceuticals&amp;rsquo; business strategy   \\n  Collaborate cross-functionally to unite resources and influence teams and stakeholders across the business    \\n   \\n \\n\\n *---*WHO YOU ARE  \\n\\n *---*\\n\\n  \\n\\n\\t  University degree (Masters preferred) in a business discipline or an equivalent education   \\n  Several years of experience in digital social media marketing, brand activation and or communications in biotech, digital or creative agency environment   \\n  Experience in a similar role in Biotech, Pharma or scientific industry   \\n  Successful track record of projects about setting and managing of a brand product on a global or broad regional scale   \\n  Persuasive business acumen including event management, brand launch, PR management as well as experience in product campaign development   \\n  Purpose driven with strong interest into biotech and tech industry, passion for new trends and upcoming technologies; Agile, flexible and authentic working style   \\n  Ability and proven track record to lead diverse teams with primarily indirect (e.g. external agencies) reporting lines   \\n  Demonstrated expertise in engaging with very senior leaders (internally and externally) coupled with strong networking skills   \\n  Excellent presentation and communication skills with the ability to create compelling messages that provides all levels of employees with a clear line of sight via the most appropriate mix of channels   \\n  Strong project management skills, results-driven, adaptable with ability to manage multiple priorities and meet deadlines as well as the flexibility and willingness to take over responsibility   \\n  Very strong communication, presentation and networking skills   \\n  Follow trends, leverage best practices and drive new approaches to deliver communications in more efficient and effective ways   \\n   \\n#LI-DE\\n    \\n \\n\\n *---*YOUR APPLICATION  \\n\\n *---*\\n    \\nAre you looking for a new challenge where you can show your passion for innovation? Are you interested in working as part of a global team to improve people&amp;rsquo;s lives? Then send us your online application including cover letter, CV and references.\\n    \\nBayer welcomes applications from all individuals, regardless of race, national origin, gender, age, physical characteristics, social origin, disability, union membership, religion, family status, pregnancy, sexual orientation, gender identity, gender expression or any unlawful criterion under applicable law. We are committed to treating all applicants fairly and avoiding discrimination.\\n    \\n \\n\\n *---*Location:  \\n\\n *---* &amp;#8203;&amp;#8203; &amp;#8203; Germany : Berlin : Berlin&amp;#8203;\\n    \\n&amp;#8203;&amp;#8203; \\n\\n *---*Division:  \\n\\n *---* &amp;#8203; Pharmaceuticals&amp;#8203;\\n    \\n \\n\\n *---*Reference Code:  \\n\\n *---* 142581&amp;#8203;',\n",
       "  'Clincase is currently seeking a Front End Developer to become part of a dynamic team. This is an exceptional opportunity for developers who seek to progress their career technically. You will be joining an innovative software development company at a pivotal point of their expansion with true career development opportunities.\\n    \\n \\n\\n *---*LOCATION  \\n\\n *---*\\n    \\nBerlin, Germany\\n    \\n \\n\\n *---*YOUR RESPONSIBILITIES  \\n\\n *---*\\n    \\nAs a Front End Developer, you will build up a Single Page Application and utilizing the latest JavaScript, CSS, and HTML technologies for our Clincase ecosystem of products.\\n    \\nThe team is building the next gen application from the ground up and you will work collaboratively with the product development team to determine the best practices for this undertaking. We are seeking a passionate team member who love having real world challenges, big goals, obsessed with the need for perfect code, and a desire to create amazing end-to-end product experience.\\n    \\nAlong with coding, you will be responsible for working with the leadership team, back-end developers and designers on our agile team structure. We love developers who lead the charge, communicating with users and conveying the most intuitive application possible is a must. Team leadership experience is welcome, but not required.\\n    \\n \\n\\n *---*YOUR PROFILE  \\n\\n *---*\\n  \\nYou hold a university degree in a Computer Science and or IT subject\\n    \\n3+ years of professional or open-source experience writing JavaScript (not just jQuery) for Single Page Architecture. Most notably AngularJS framework but also React, or anything similar\\n  \\nExperience with CSS framework such as LESS, Sass, etc. is a huge plus\\n  \\nFirm grasp of framework URL based routing principles\\n  \\nFamiliarity with standard JavaScript async patterns (closures, callbacks, promises, error handling, etc. including new ES6 features)\\n  \\nModerate CS fundamentals and an object oriented language (think an undergrad CS degree, or similar amount of work experience)\\n  \\nExperience coding against RESTful APIs or service oriented middle tiers\\n  \\nNever ending desire to self-educate on the latest list of web technologies like HTML, CSS, JavaScript frameworks and bleeding edge browser features idiosyncrasies\\n  \\n \\n\\n *---*WHAT WE OFFER  \\n\\n *---*\\n  \\nBe part of an international team of ambitious, creative team members\\n  \\nPossibility to make a direct impact on the product &amp;amp; company revenues\\n  \\nA high level of responsibility from the very first day\\n  \\nAgile, focused, yet relaxed atmosphere\\n  \\nAnd&amp;hellip; a large reservoir of free drinks, snacks and fruits!\\n  \\n \\n\\n *---*WHO ARE WE?  \\n\\n *---*\\n    \\nQuadratek Data Solutions (Clincase) is a software development company based in Berlin that has developed software for electronic data capture in clinical trials. Our software products provide innovative, e-Clinical Technology Solutions to pharmaceutical and biotechnology companies, contract research organizations (CROs), and scientific and academic research institutions around the world. Our mission is to create the best e-Clinical solution that would transform data management and simplify the way clinical trials are conducted.\\n    \\nWe are a small company with a big impact located in Berlin the European center of technology, culture and government. Ours is a company culture that encourages open channels for discussion, free flow of ideas and a real chance to impact, develop and innovate solutions inside a rapidly developing and evolving industry.\\n    \\n \\n\\n *---*HOW TO APPLY  \\n\\n *---*\\n    \\nPlease apply through the career link below with your CV, cover letter, salary expectations, and earliest possible starting date. Should you have any questions, you can send an email at info@clincase.com',\n",
       "  'BIOTRONIK is one of the leading manufacturers of cardio- and endovascular implants and catheters for cardiac rhythm management, electrophysiology and vascular intervention. As a globally active company headquartered in Berlin, Germany, we develop, produce and distribute high-quality medical products based on the latest technology and research. Our success is based on the competence and results-oriented cooperation of our employees.\\n    \\nThe Value, Access &amp;amp; Pricing division provides strategic, tactical and content-related support for the individual BIOTRONIK country organizations and for the entire product portfolio. Our activities focus on the further development of economic benefit arguments and their communication to various decision-making groups as well as consulting and support for local market access and sales activities.\\n    \\nYour Responsibilities\\n    \\nIdentification and presentation of clinical and economic benefits of our products\\n  \\nDevelopment of appropriate instruments for cost coverage negotiations with non-clinical stakeholders\\n  \\nDevelopment of existing evidence and tools\\n  \\nSupport of local market access and sales activities\\n  \\nAnalysis and monitoring of health systems\\n  \\nDevelopment and execution of training courses\\n    \\nYour Profile\\n    \\nStudies in (health-) economics, medicine, public health, biotechnology or pharmacy or comparable\\n  \\nRelevant professional experience in a comparable position in the medical technology or pharma sector\\n  \\nVery good knowledge of health economics and international reimbursement systems\\n  \\nVery good English and basic German skills\\n    \\nWhat we offer\\n    \\nDeveloping yourself professionally through exciting tasks\\n  \\nComprehensive health promotion\\n    \\nAre you interested? Please apply online through our application management system! We are looking forward to welcoming you.\\n    \\n \\n\\n *---*Location:  \\n\\n *---* Berlin | Working hours: Full-time | Type of contract: Unlimited\\n    \\n \\n\\n *---*Apply now under:  \\n\\n *---* www.biotronik.com careers\\n    \\n \\n\\n *---*Job ID:  \\n\\n *---* 32183 | Contact: Anna-Luise Richter | Tel. +49 (0) 30 68905-3535\\n    \\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity or expression, national origin, disability status, protected veteran status, genetic information, or any other characteristic protected by law.',\n",
       "  'We are hiring\\n    \\nAt PERMACON you will find the seriousness and security of a personnel consultancy with an expertise of over 25 years.\\n    \\nOur customer is a global corporation specializing in biotechnology research company and has specialized contract work and other services.\\n    \\nWe are looking for a laboratory technician (m f d) for bioanalytical analyzes and their validation for the clinical trials department in Berlin (City West) to September 1st, 2020.\\n    \\nYour typical duties include\\n    \\nDevelop, validate and conduct flow cytometry assays involving different types of biological samples e.g. immune cell phenotyping, activation assays, receptor occupancy and depletion assays, intracellular cytokine detection etc.\\n    \\nIsolation and Cryopreservation of Mononuclear Cells of Peripheral Blood (PBMC)\\n    \\nLiterature research to develop bio-analytical test procedures\\n    \\nDetailed documentation of the process steps and evaluations of the analyzes using FlowJo software\\n    \\nEnsuring that the data generated and passed on to customers comply with the internal quality control (QC) and quality assurance procedures (QS)\\n    \\nPerform daily GHK tasks in the laboratory and follow strict health and safety procedures\\n    \\nClose cooperation with the project managers to discuss and review the study phases, reports, analysis results\\n    \\nOur required criteria\\n  \\nCompleted training as a biology laboratory technician (m f d) or comparable degree\\n  \\nAt least 2-3 years of professional experience in clinical trials\\n  \\nExperience in the use of laboratory equipment (centrifuges, flow cytometry, ELISPOT plate readers, cell culture equipment, microscopes) as well as the ELISA, multiplex biomarker and cytokine assays, knowledge of immunogenicity, toxicity and PBMC isolation also advantageous\\n  \\nVery good knowledge of English, as the company language is English\\n  \\nGood knowledge of German at least A1-level\\n  \\nApplication of all hygiene and protection regulations\\n  \\nYour perspective\\n  \\nDirect placement full-time\\n  \\nWork place in the City-West, state-of-the-art laboratory with the latest analysis devices\\n  \\nTemporary contract for 2 years with the option to extend\\n  \\nInternational company\\n    \\nQualified advice, competent and friendly personnel consultants the PERMACON - up to the setting and beyond\\n    \\nYour Contact Person\\n    \\nGerrit Ninja Maronde\\n    \\nHead of Medical Department\\n    \\n \\n\\n *---*T: +49 30 226679-35  \\n\\n *---*\\n    \\nPermacon GmbH\\n    \\nGeorgenstra&amp;szlig;e 22\\n    \\n10117 Berlin',\n",
       "  'We are hiring\\n    \\nAt PERMACON you will find the seriousness and security of a personnel consultancy with an expertise of over 25 years.\\n    \\nOur customer is a global corporation specializing in biotechnology research company and has specialized contract work and other services.\\n    \\nWe are looking for a senior scientist (m f d) for the analysis of clinical studies in the &amp;quot;Soluble Biomarkers&amp;quot; department of our customer in Berlin-Westend.\\n    \\nYour typical duties include\\n    \\nDevelopment, validation and application of methods to clinical samples in collaboration with and under the guidance of senior scientists, unit heads and the principal scientist\\n    \\nDetailed documentation of the process steps and evaluations of the analyses\\n    \\nEnsure ongoing compliance with regulatory guidelines (FDA and EMA) for Bioanalysis\\n    \\nDoing literature searches for assays reagents which can be applied to the development of bioanalytical tests\\n    \\nEnsuring the proper use of equipment and arranging performing ensuring the routine service of equipment used\\n    \\nArchiving of study data after completion of the project\\n    \\nRegular quality controls to ensure the audit trail\\n    \\nClose cooperation with the project managers to discuss and review the study phases, reports and analysis results\\n    \\nOur required criteria\\n    \\nMinimum Master of Science or Master of Medical Sciene (m f d)\\n    \\n4-5 years&amp;rsquo; experience in Bioanalysis (particularly Pharmacokinetics and Immunogenicity) within the regulatory environment of clinical trials is absolutely essential\\n    \\nThis should include having a comprehensive knowledge and understanding of regulatory guidelines\\n    \\nExperience in the use of laboratory equipment (centrifuges, flow cytometry, ELISPOT plate readers, cell culture equipment, and microscopes) as well as the ELISA, multiplex biomarker and cytokine assays, knowledge of immunogenicity, toxicity and PBMC isolation also advantageous\\n    \\nVery good knowledge of English, as the company language is English\\n    \\nGood knowledge of German at least A1-level\\n    \\nApplication of all hygiene and protection regulations\\n    \\nYour perspective\\n  \\nDirect placement full-time\\n    \\nWorkplace in the City-West, state-of-the-art laboratory with the latest analysis devices\\n    \\nLimited contract for 2 years with the option to extend\\n    \\nExciting challenge in an international company\\n    \\nQualified advice, competent and friendly personnel consultants of the PERMACON - up to the setting and beyond\\n    \\nYour Contact Person\\n    \\nGerrit Ninja Maronde\\n    \\nHead of Medical Department\\n    \\n \\n\\n *---*T: +49 30 226679-35  \\n\\n *---*\\n    \\nPermacon GmbH\\n    \\nGeorgenstra&amp;szlig;e 22\\n    \\n10117 Berlin'],\n",
       " [datetime.datetime(2020, 7, 29, 11, 46, 26, 861771),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 29, 257026),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 31, 373281),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 33, 890353),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 36, 100561),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 38, 113918),\n",
       "  datetime.datetime(2020, 7, 29, 11, 46, 41, 419087)],\n",
       " ['2020-07-29',\n",
       "  '2020-07-28',\n",
       "  '2020-07-29',\n",
       "  '2020-07-28',\n",
       "  '2020-07-29',\n",
       "  '2020-07-28',\n",
       "  '2020-07-28'],\n",
       " ['2020-08-28',\n",
       "  '2020-08-28',\n",
       "  '2020-08-28',\n",
       "  '2020-08-28',\n",
       "  '2020-08-28',\n",
       "  '2020-08-28',\n",
       "  '2020-08-28'],\n",
       " ['https://www.glassdoor.de/job-listing/dm-132-20b-research-associate-postdoc-chronic-and-genetic-kidney-disease-charité-JV_IC2622109_KO0,72_KE73,80.htm?jl=3636213042',\n",
       "  'https://www.glassdoor.de/job-listing/senior-specialist-apheresis-audit-germany-location-flexible-bristol-myers-squibb-JV_IC2622109_KO0,59_KE60,80.htm?jl=3635357570',\n",
       "  'https://www.glassdoor.de/job-listing/head-of-external-activation-and-identity-management-director-bayer-JV_IC2622109_KO0,60_KE61,66.htm?jl=3548761211',\n",
       "  'https://www.glassdoor.de/job-listing/front-end-developer-mfd-clincase-JV_IC2622109_KO0,23_KE24,32.htm?jl=3589386064',\n",
       "  'https://www.glassdoor.de/job-listing/senior-manager-health-economics-market-access-mfd-biotronik-JV_IC2622109_KO0,49_KE50,59.htm?jl=3612941022',\n",
       "  'https://www.glassdoor.de/job-listing/laboratory-technician-mfd-permacon-gmbh-berlin-JV_IC2622109_KO0,25_KE26,46.htm?jl=3635236464',\n",
       "  'https://www.glassdoor.de/job-listing/senior-scientist-mfd-permacon-gmbh-berlin-JV_IC2622109_KO0,20_KE21,41.htm?jl=3635236475'],\n",
       " ['16', '16', '16', '16', '16', '16', '16'],\n",
       " ['52.5177', '52.5177', '52.5177', '52.5177', '52.5177', '52.5177', '52.5177'],\n",
       " ['13.4055', '13.4055', '13.4055', '13.4055', '13.4055', '13.4055', '13.4055'],\n",
       " [])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populate_temp_tables(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================creating pandas dataframe with all the temp tables populated before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_glassdoor = pd.DataFrame({'job_name' : job,\n",
    "                               'company_name' : company,\n",
    "                               'job_descr' : job_d,\n",
    "                               'timestamp': time_s,\n",
    "                               'datePosted': datePosted_t,\n",
    "                               'validThrough' : validThrough_t,\n",
    "                               'job_url' : job_url_t,\n",
    "                               'place_name' : place,\n",
    "                               'place_name_region' : place_name_region_t,\n",
    "                               'latitude_' : latitude_t,\n",
    "                               'longitude' : longitude_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   job_name           7 non-null      object        \n",
      " 1   company_name       7 non-null      object        \n",
      " 2   job_descr          7 non-null      object        \n",
      " 3   timestamp          7 non-null      datetime64[ns]\n",
      " 4   datePosted         7 non-null      object        \n",
      " 5   validThrough       7 non-null      object        \n",
      " 6   job_url            7 non-null      object        \n",
      " 7   place_name         7 non-null      object        \n",
      " 8   place_name_region  7 non-null      object        \n",
      " 9   latitude_          7 non-null      object        \n",
      " 10  longitude          7 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(10)\n",
      "memory usage: 744.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "jobs_glassdoor.info() #double checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating file name with timestamp info for later comparison\n",
    "def gen_h5_file_with_timestamp(name='name'):\n",
    "    timestamp = datetime.datetime.now()\n",
    "    ts1 = timestamp.strftime(\"%A%d%B%Y%m\")\n",
    "    ts2 = timestamp.strftime(\"%H\")\n",
    "    ts3 = timestamp.strftime(\"%M\")\n",
    "    ts4 = timestamp.strftime(\"%S\")\n",
    "    file_name= name + ts1 +\"-\"+ ts2+\"-\"+ ts3+\"-\"+ ts4+\".h5\"\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glassdoor-Wednesday29July202007-11-46-53.h5'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name= gen_h5_file_with_timestamp(name='glassdoor-')\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframe in .h5 file for later use\n",
    "jobs_glassdoor.to_hdf('./glass/'+file_name, key='df', mode='w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading last( creation time) two dfs for comparison\n",
    "def read_two_last_dfs():\n",
    "    files_sorted=list_per_time()\n",
    "    f1=files_sorted[-2:-1]\n",
    "    f2=files_sorted[-1:]\n",
    "    df1=pd.read_hdf(f1[0], 'df')\n",
    "    df2=pd.read_hdf(f2[0], 'df')\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lubuntu/scrap/glass/glassdoor-Wednesday29July202007-11-45-38.h5', '/home/lubuntu/scrap/glass/glassdoor-Wednesday29July202007-11-46-53.h5']\n"
     ]
    }
   ],
   "source": [
    "df1, df2=read_two_last_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   job_name           0 non-null      float64\n",
      " 1   company_name       0 non-null      float64\n",
      " 2   job_descr          0 non-null      float64\n",
      " 3   timestamp          0 non-null      float64\n",
      " 4   datePosted         0 non-null      float64\n",
      " 5   validThrough       0 non-null      float64\n",
      " 6   job_url            0 non-null      float64\n",
      " 7   place_name         0 non-null      float64\n",
      " 8   place_name_region  0 non-null      float64\n",
      " 9   latitude_          0 non-null      float64\n",
      " 10  longitude          0 non-null      float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 0.0 bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7 entries, 0 to 6\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   job_name           7 non-null      object        \n",
      " 1   company_name       7 non-null      object        \n",
      " 2   job_descr          7 non-null      object        \n",
      " 3   timestamp          7 non-null      datetime64[ns]\n",
      " 4   datePosted         7 non-null      object        \n",
      " 5   validThrough       7 non-null      object        \n",
      " 6   job_url            7 non-null      object        \n",
      " 7   place_name         7 non-null      object        \n",
      " 8   place_name_region  7 non-null      object        \n",
      " 9   latitude_          7 non-null      object        \n",
      " 10  longitude          7 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(10)\n",
      "memory usage: 672.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of loaded dfs\n",
    "df1.info(), df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "Name: job_url, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking what new/diffrent records(False) are new in df2\n",
    "df2['job_url'].isin(df1['job_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_descr</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datePosted</th>\n",
       "      <th>validThrough</th>\n",
       "      <th>job_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_name_region</th>\n",
       "      <th>latitude_</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DM.132.20b Research Associate (Postdoc) - Chro...</td>\n",
       "      <td>Charité</td>\n",
       "      <td>Unternehmensbeschreibung       Die Charit&amp;am...</td>\n",
       "      <td>2020-07-29 11:46:26.861771</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/dm-132-20...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Specialist, Apheresis Audit - Germany (...</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>At Bristol Myers Squibb, we are inspired by a ...</td>\n",
       "      <td>2020-07-29 11:46:29.257026</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/senior-sp...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Head of External Activation and Identity Manag...</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>\\n\\n *---*Bayer is a global enterprise with c...</td>\n",
       "      <td>2020-07-29 11:46:31.373281</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/head-of-e...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRONT END DEVELOPER (M/F/D)</td>\n",
       "      <td>Clincase</td>\n",
       "      <td>Clincase is currently seeking a Front End Deve...</td>\n",
       "      <td>2020-07-29 11:46:33.890353</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/front-end...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Manager Health Economics &amp; Market Acces...</td>\n",
       "      <td>BIOTRONIK</td>\n",
       "      <td>BIOTRONIK is one of the leading manufacturers ...</td>\n",
       "      <td>2020-07-29 11:46:36.100561</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/senior-ma...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laboratory technician (m/f/d)</td>\n",
       "      <td>PERMACON GmbH Berlin</td>\n",
       "      <td>We are hiring\\n    \\nAt PERMACON you will find...</td>\n",
       "      <td>2020-07-29 11:46:38.113918</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/laborator...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior scientist (m/f/d)</td>\n",
       "      <td>PERMACON GmbH Berlin</td>\n",
       "      <td>We are hiring\\n    \\nAt PERMACON you will find...</td>\n",
       "      <td>2020-07-29 11:46:41.419087</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>https://www.glassdoor.de/job-listing/senior-sc...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>16</td>\n",
       "      <td>52.5177</td>\n",
       "      <td>13.4055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_name          company_name  \\\n",
       "0  DM.132.20b Research Associate (Postdoc) - Chro...               Charité   \n",
       "1  Senior Specialist, Apheresis Audit - Germany (...  Bristol-Myers Squibb   \n",
       "2  Head of External Activation and Identity Manag...                 Bayer   \n",
       "3                        FRONT END DEVELOPER (M/F/D)              Clincase   \n",
       "4  Senior Manager Health Economics & Market Acces...             BIOTRONIK   \n",
       "5                      Laboratory technician (m/f/d)  PERMACON GmbH Berlin   \n",
       "6                           Senior scientist (m/f/d)  PERMACON GmbH Berlin   \n",
       "\n",
       "                                           job_descr  \\\n",
       "0    Unternehmensbeschreibung       Die Charit&am...   \n",
       "1  At Bristol Myers Squibb, we are inspired by a ...   \n",
       "2   \\n\\n *---*Bayer is a global enterprise with c...   \n",
       "3  Clincase is currently seeking a Front End Deve...   \n",
       "4  BIOTRONIK is one of the leading manufacturers ...   \n",
       "5  We are hiring\\n    \\nAt PERMACON you will find...   \n",
       "6  We are hiring\\n    \\nAt PERMACON you will find...   \n",
       "\n",
       "                   timestamp  datePosted validThrough  \\\n",
       "0 2020-07-29 11:46:26.861771  2020-07-29   2020-08-28   \n",
       "1 2020-07-29 11:46:29.257026  2020-07-28   2020-08-28   \n",
       "2 2020-07-29 11:46:31.373281  2020-07-29   2020-08-28   \n",
       "3 2020-07-29 11:46:33.890353  2020-07-28   2020-08-28   \n",
       "4 2020-07-29 11:46:36.100561  2020-07-29   2020-08-28   \n",
       "5 2020-07-29 11:46:38.113918  2020-07-28   2020-08-28   \n",
       "6 2020-07-29 11:46:41.419087  2020-07-28   2020-08-28   \n",
       "\n",
       "                                             job_url place_name  \\\n",
       "0  https://www.glassdoor.de/job-listing/dm-132-20...     Berlin   \n",
       "1  https://www.glassdoor.de/job-listing/senior-sp...     Berlin   \n",
       "2  https://www.glassdoor.de/job-listing/head-of-e...     Berlin   \n",
       "3  https://www.glassdoor.de/job-listing/front-end...     Berlin   \n",
       "4  https://www.glassdoor.de/job-listing/senior-ma...     Berlin   \n",
       "5  https://www.glassdoor.de/job-listing/laborator...     Berlin   \n",
       "6  https://www.glassdoor.de/job-listing/senior-sc...     Berlin   \n",
       "\n",
       "  place_name_region latitude_ longitude  \n",
       "0                16   52.5177   13.4055  \n",
       "1                16   52.5177   13.4055  \n",
       "2                16   52.5177   13.4055  \n",
       "3                16   52.5177   13.4055  \n",
       "4                16   52.5177   13.4055  \n",
       "5                16   52.5177   13.4055  \n",
       "6                16   52.5177   13.4055  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking what records are new in df2 compared to df1(~not in) as overview\n",
    "df2.loc[~df2['job_url'].isin(df1['job_url'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============links to new jobs since last checking=============\n",
      "\n",
      "0 --> https://www.glassdoor.de/job-listing/dm-132-20b-research-associate-postdoc-chronic-and-genetic-kidney-disease-charité-JV_IC2622109_KO0,72_KE73,80.htm?jl=3636213042\n",
      "1 --> https://www.glassdoor.de/job-listing/senior-specialist-apheresis-audit-germany-location-flexible-bristol-myers-squibb-JV_IC2622109_KO0,59_KE60,80.htm?jl=3635357570\n",
      "2 --> https://www.glassdoor.de/job-listing/head-of-external-activation-and-identity-management-director-bayer-JV_IC2622109_KO0,60_KE61,66.htm?jl=3548761211\n",
      "3 --> https://www.glassdoor.de/job-listing/front-end-developer-mfd-clincase-JV_IC2622109_KO0,23_KE24,32.htm?jl=3589386064\n",
      "4 --> https://www.glassdoor.de/job-listing/senior-manager-health-economics-market-access-mfd-biotronik-JV_IC2622109_KO0,49_KE50,59.htm?jl=3612941022\n",
      "5 --> https://www.glassdoor.de/job-listing/laboratory-technician-mfd-permacon-gmbh-berlin-JV_IC2622109_KO0,25_KE26,46.htm?jl=3635236464\n",
      "6 --> https://www.glassdoor.de/job-listing/senior-scientist-mfd-permacon-gmbh-berlin-JV_IC2622109_KO0,20_KE21,41.htm?jl=3635236475\n"
     ]
    }
   ],
   "source": [
    "print('=============links to new jobs since last checking=============\\n')\n",
    "for x,item in enumerate(df2.job_url.values[~df2['job_url'].isin(df1['job_url'])]):\n",
    "    print(x, '-->',item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating file name with timestamp info for later comparison\n",
    "def gen_md_file_with_timestamp(name='name'):\n",
    "    timestamp = datetime.datetime.now()\n",
    "    ts1 = timestamp.strftime(\"%A%d%B%Y%m\")\n",
    "    ts2 = timestamp.strftime(\"%H\")\n",
    "    ts3 = timestamp.strftime(\"%M\")\n",
    "    ts4 = timestamp.strftime(\"%S\")\n",
    "    file_name= name + ts1 +\"-\"+ ts2+\"-\"+ ts3+\"-\"+ ts4+\".md\"\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selected-bio-Wednesday29July202007-11-49-51.md'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_file_name= gen_md_file_with_timestamp(name='selected-bio-')\n",
    "md_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====list of the interesting columns which should be displayed processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3= list(df2.job_name.values+'    \\n'+df2.company_name.values+ '    \\n'+df2.job_url.values+'   '+df2.job_descr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now()\n",
    "ts1 = timestamp.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def df_date_filter(_date= ts1): # you could give date in a format '2020-07-21'\n",
    "    \n",
    "\n",
    "    l4= list(df2.job_name.values[df2.datePosted==ts1]+\n",
    "             '    \\n'+df2.company_name.values[df2.datePosted==ts1]+\n",
    "             '    \\n'+df2.job_url.values[df2.datePosted==ts1]+\n",
    "             '    \\n'+df2.job_descr.values[df2.datePosted==ts1])\n",
    "    return l4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_Table_to_file(temp_file=l3): #saving content to md file\n",
    "    \n",
    "    with open('./glass/'+md_file_name, 'a') as f:\n",
    "        for x, item in enumerate(temp_file):\n",
    "            temp= '\\n'+'> ##  Job nr:'+str(x+1)+ '/'+str(len(temp_file))+'------------------------------   \\n'\n",
    "            temp1='    \\n'\n",
    "            f.write(temp)\n",
    "            f.write(md_file_name) \n",
    "            f.write(temp1)\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========Saving subset of jobs from today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_Table_to_file(df_date_filter(_date= ts1)) # you could give date in a format '2020-07-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========Saving subset of jobs from particular day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_Table_to_file(df_date_filter(_date= '2020-07-29')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====There is possibility to define a uiversal filter between df1 and df2 ie between the present and last df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1= ~df2['job_url'].isin(df1['job_url'])\n",
    "\n",
    "filter2= df2.datePosted=='2020-07-29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_difference_filter(filter=filter1): # you could give date in a format '2020-07-21'\n",
    "    \n",
    "\n",
    "    l4= list(df2.job_name.values[filter]+\n",
    "             '    \\n'+df2.company_name.values[filter]+\n",
    "             '    \\n'+df2.job_url.values[filter]+\n",
    "             '    \\n'+df2.job_descr.values[filter])\n",
    "    return l4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate file with diffrence to last \n",
    "md_file_name= gen_md_file_with_timestamp(name='selected-ml-diffrerence-')\n",
    "md_file_name\n",
    "save_Table_to_file(df_difference_filter(filter1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
